{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import vw_c3d_newnetwork\n",
    "import vw_c3d_tools\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "gpu_num = 1\n",
    "#MAX_STEPS = 10000\n",
    "NUM_FRAMES_PER_CLIP = 16\n",
    "N_CLASSE = 9\n",
    "CROP_SIZE = 112\n",
    "CHANNELS = 3\n",
    "MAX_EPOCHS = 100\n",
    "INIT_LEARNINGRATE = 3e-3\n",
    "\n",
    "train_log_dir = './logs//train//'\n",
    "val_log_dir = './logs//val//'\n",
    "model_dir = './models/'\n",
    "model_filename = './models/'\n",
    "is_finetune = False\n",
    "\n",
    "def placeholder_inputs(batch_size):\n",
    "    images_placeholder = tf.placeholder(tf.float32, shape=(BATCH_SIZE,\n",
    "                                                           NUM_FRAMES_PER_CLIP,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CROP_SIZE,\n",
    "                                                           CHANNELS))\n",
    "    labels_placeholder = tf.placeholder(tf.int64, shape=[BATCH_SIZE, N_CLASSE])\n",
    "    return images_placeholder, labels_placeholder\n",
    "\n",
    "def train():\n",
    "    with tf.Graph().as_default():\n",
    "        #建立读取数据的pipeline，在训练过程中迭代器可以自动读取数据\n",
    "        train_images_batch, train_labels_batch, _, _, _, train_total_num = input_data.read_clip_and_label(\n",
    "                                                      filename='list/train.list',\n",
    "                                                      batch_size=BATCH_SIZE * gpu_num,\n",
    "                                                      num_frames_per_clip=NUM_FRAMES_PER_CLIP,\n",
    "                                                      crop_size=CROP_SIZE,\n",
    "                                                      shuffle=True\n",
    "                                                      )\n",
    "        val_images_batch, val_labels_batch, _, _, _, val_total_num= input_data.read_clip_and_label(\n",
    "                                                      filename='list/test.list',\n",
    "                                                      batch_size=BATCH_SIZE * gpu_num,\n",
    "                                                      num_frames_per_clip=NUM_FRAMES_PER_CLIP,\n",
    "                                                      crop_size=CROP_SIZE,\n",
    "                                                      shuffle=True\n",
    "                                                      )\n",
    " \n",
    "\n",
    "        #定义学习率\n",
    "        global_step = tf.Variable(0, name='global_step', trainable=False) \n",
    "        initial_learning_rate = INIT_LEARNINGRATE       #初始学习率\n",
    "        learning_rate_decay_rate = 0.90                 #学习率衰减率\n",
    "        step_of_epoch = math.floor(train_total_num / BATCH_SIZE)    #迭代完一次所有样本需要的步数\n",
    "        learning_rate_decay_steps = step_of_epoch       #学习率衰减一次所需要的步数\n",
    "        learning_rate = tf.train.exponential_decay(initial_learning_rate,\n",
    "                    global_step, \n",
    "                    learning_rate_decay_steps,\n",
    "                    learning_rate_decay_rate,staircase=True)              \n",
    "        \n",
    "        #将数据映射成tenor形式,并进行one-hot编码\n",
    "        train_images_batch = tf.cast(train_images_batch,dtype=tf.float32)\n",
    "        train_labels_batch = tf.one_hot(train_labels_batch, depth= N_CLASSE)\n",
    "        train_labels_batch = tf.cast(train_labels_batch,dtype=tf.int32)\n",
    "        val_images_batch = tf.cast(val_images_batch,dtype=tf.float32)\n",
    "        val_labels_batch = tf.one_hot(val_labels_batch, depth= N_CLASSE)\n",
    "        val_labels_batch = tf.cast(val_labels_batch,dtype=tf.int32)\n",
    "        \n",
    "        #构建logits、loss、accuracy、train_op\n",
    "        logits = vw_c3d_newnetwork.C3D_MODEL(train_images_batch,N_CLASSE)\n",
    "        loss = vw_c3d_tools.loss(logits, train_labels_batch)\n",
    "        accuracy = vw_c3d_tools.accuracy(logits,train_labels_batch)\n",
    "        train_op = vw_c3d_tools.optimize(loss,learning_rate,global_step)\n",
    "        \n",
    "        #构建数据和标签的place_holder \n",
    "        images_placeholder, labels_placeholder = placeholder_inputs(BATCH_SIZE * gpu_num)\n",
    "        \n",
    "        #准备存储模型\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        #设置绘图的op\n",
    "        summary_op = tf.summary.merge_all()\n",
    "\n",
    "        #初始化所有变量，并开启会话\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        if is_finetune:\n",
    "            saver.restore(sess, model_filename)\n",
    "        \n",
    "        #tensoboard绘图的writer\n",
    "        tra_summary_writer = tf.summary.FileWriter(train_log_dir, sess.graph)\n",
    "        val_summary_writer = tf.summary.FileWriter(val_log_dir, sess.graph)\n",
    "        \n",
    "        #打印一些基本信息\n",
    "        MAX_STEPS = int(MAX_EPOCHS * step_of_epoch)\n",
    "        print(\"MAX_STEPS: \",MAX_STEPS)\n",
    "        print(\"MAX_EPOCHS: \", MAX_EPOCHS)\n",
    "        print(\"step_of_epoch\", step_of_epoch)\n",
    "        print(\"Train samples: \", train_total_num)\n",
    "        print(\"Val samples\", val_total_num)\n",
    "        \n",
    "        for step in range(MAX_STEPS):\n",
    "            start_time = time.time()\n",
    "            tra_images,tra_labels = sess.run([train_images_batch,train_labels_batch])\n",
    "            _, train_loss, train_accuracy = sess.run([train_op,loss,accuracy], feed_dict ={\n",
    "                                                          images_placeholder: tra_images,\n",
    "                                                          labels_placeholder: tra_labels\n",
    "                                                          })\n",
    "            duration = time.time() - start_time\n",
    "            print('Step %d: %.3f sec' % (step, duration))\n",
    "            if step % 10 == 0 or (step + 1) == MAX_STEPS:\n",
    "                print ('Step: %d, train_loss: %.4f, train_accuracy: %.4f%%' % (step, train_loss, train_accuracy))\n",
    "                summary_str = sess.run(summary_op)\n",
    "                tra_summary_writer.add_summary(summary_str, step)\n",
    "            \n",
    "            if step % 50 == 0 or (step + 1) == MAX_STEPS:\n",
    "                val_images,val_labels=sess.run([val_images_batch,val_labels_batch])\n",
    "                val_loss, val_acc = sess.run([loss, accuracy], feed_dict={\n",
    "                                                      images_placeholder: val_images,\n",
    "                                                      labels_placeholder: val_labels})\n",
    "                summary_str = sess.run(summary_op)\n",
    "                val_summary_writer.add_summary(summary_str, step)\n",
    "                print('**  Step %d, val_loss = %.2f, val_accuracy = %.2f%%  **' %(step, val_loss, val_acc))\n",
    "            if step % (step_of_epoch*3) == 0 or (step + 1) == MAX_STEPS:\n",
    "                checkpoint_path = os.path.join(model_dir, 'model')\n",
    "                saver.save(sess, checkpoint_path, global_step=step)\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_STEPS:  7800\n",
      "MAX_EPOCHS:  100\n",
      "step_of_epoch 78\n",
      "Train samples:  1260\n",
      "Val samples 538\n",
      "Step 0: 2.527 sec\n",
      "Step: 0, train_loss: 5.5642, train_accuracy: 6.2500%\n",
      "**  Step 0, val_loss = 5.21, val_accuracy = 6.25%  **\n",
      "Step 1: 1.124 sec\n",
      "Step 2: 1.128 sec\n",
      "Step 3: 0.981 sec\n",
      "Step 4: 1.006 sec\n",
      "Step 5: 1.001 sec\n",
      "Step 6: 1.067 sec\n",
      "Step 7: 1.045 sec\n",
      "Step 8: 0.991 sec\n",
      "Step 9: 0.992 sec\n",
      "Step 10: 0.992 sec\n",
      "Step: 10, train_loss: 6.7070, train_accuracy: 43.7500%\n",
      "Step 11: 1.022 sec\n",
      "Step 12: 1.018 sec\n",
      "Step 13: 1.153 sec\n",
      "Step 14: 1.017 sec\n",
      "Step 15: 1.027 sec\n",
      "Step 16: 1.078 sec\n",
      "Step 17: 1.040 sec\n",
      "Step 18: 1.016 sec\n",
      "Step 19: 1.127 sec\n",
      "Step 20: 1.019 sec\n",
      "Step: 20, train_loss: 7.7721, train_accuracy: 56.2500%\n",
      "Step 21: 1.057 sec\n",
      "Step 22: 1.014 sec\n",
      "Step 23: 1.191 sec\n",
      "Step 24: 1.133 sec\n",
      "Step 25: 1.193 sec\n",
      "Step 26: 1.004 sec\n",
      "Step 27: 1.158 sec\n",
      "Step 28: 1.082 sec\n",
      "Step 29: 0.993 sec\n",
      "Step 30: 1.053 sec\n",
      "Step: 30, train_loss: 7.6158, train_accuracy: 75.0000%\n",
      "Step 31: 1.061 sec\n",
      "Step 32: 1.031 sec\n",
      "Step 33: 1.197 sec\n",
      "Step 34: 0.979 sec\n",
      "Step 35: 1.036 sec\n",
      "Step 36: 0.996 sec\n",
      "Step 37: 0.993 sec\n",
      "Step 38: 1.017 sec\n",
      "Step 39: 0.993 sec\n",
      "Step 40: 1.011 sec\n",
      "Step: 40, train_loss: 7.1073, train_accuracy: 75.0000%\n",
      "Step 41: 1.025 sec\n",
      "Step 42: 1.011 sec\n",
      "Step 43: 1.038 sec\n",
      "Step 44: 0.999 sec\n",
      "Step 45: 1.210 sec\n",
      "Step 46: 1.004 sec\n",
      "Step 47: 1.062 sec\n",
      "Step 48: 1.157 sec\n",
      "Step 49: 0.993 sec\n",
      "Step 50: 1.091 sec\n",
      "Step: 50, train_loss: 6.6127, train_accuracy: 87.5000%\n",
      "**  Step 50, val_loss = 6.59, val_accuracy = 87.50%  **\n",
      "Step 51: 1.071 sec\n",
      "Step 52: 1.193 sec\n",
      "Step 53: 1.106 sec\n",
      "Step 54: 1.016 sec\n",
      "Step 55: 1.081 sec\n",
      "Step 56: 1.042 sec\n",
      "Step 57: 1.012 sec\n",
      "Step 58: 1.141 sec\n",
      "Step 59: 1.119 sec\n",
      "Step 60: 1.124 sec\n",
      "Step: 60, train_loss: 6.5098, train_accuracy: 81.2500%\n",
      "Step 61: 1.092 sec\n",
      "Step 62: 1.072 sec\n",
      "Step 63: 1.151 sec\n",
      "Step 64: 1.168 sec\n",
      "Step 65: 1.115 sec\n",
      "Step 66: 1.166 sec\n",
      "Step 67: 1.020 sec\n",
      "Step 68: 1.171 sec\n",
      "Step 69: 1.013 sec\n",
      "Step 70: 1.006 sec\n",
      "Step: 70, train_loss: 6.1801, train_accuracy: 87.5000%\n",
      "Step 71: 1.058 sec\n",
      "Step 72: 1.112 sec\n",
      "Step 73: 1.132 sec\n",
      "Step 74: 1.185 sec\n",
      "Step 75: 1.114 sec\n",
      "Step 76: 0.996 sec\n",
      "Step 77: 1.003 sec\n",
      "Step 78: 1.000 sec\n",
      "Step 79: 1.015 sec\n",
      "Step 80: 1.096 sec\n",
      "Step: 80, train_loss: 6.0882, train_accuracy: 81.2500%\n",
      "Step 81: 1.031 sec\n",
      "Step 82: 1.096 sec\n",
      "Step 83: 1.024 sec\n",
      "Step 84: 1.089 sec\n",
      "Step 85: 1.144 sec\n",
      "Step 86: 1.060 sec\n",
      "Step 87: 0.989 sec\n",
      "Step 88: 0.996 sec\n",
      "Step 89: 1.169 sec\n",
      "Step 90: 1.145 sec\n",
      "Step: 90, train_loss: 5.9098, train_accuracy: 87.5000%\n",
      "Step 91: 1.055 sec\n",
      "Step 92: 0.998 sec\n",
      "Step 93: 1.173 sec\n",
      "Step 94: 1.101 sec\n",
      "Step 95: 1.125 sec\n",
      "Step 96: 1.028 sec\n",
      "Step 97: 1.019 sec\n",
      "Step 98: 1.195 sec\n",
      "Step 99: 1.071 sec\n",
      "Step 100: 1.095 sec\n",
      "Step: 100, train_loss: 5.6489, train_accuracy: 87.5000%\n",
      "**  Step 100, val_loss = 5.61, val_accuracy = 87.50%  **\n",
      "Step 101: 1.073 sec\n",
      "Step 102: 1.032 sec\n",
      "Step 103: 1.131 sec\n",
      "Step 104: 1.093 sec\n",
      "Step 105: 1.168 sec\n",
      "Step 106: 1.146 sec\n",
      "Step 107: 1.004 sec\n",
      "Step 108: 1.105 sec\n",
      "Step 109: 0.984 sec\n",
      "Step 110: 1.035 sec\n",
      "Step: 110, train_loss: 5.9850, train_accuracy: 75.0000%\n",
      "Step 111: 1.043 sec\n",
      "Step 112: 0.998 sec\n",
      "Step 113: 1.001 sec\n",
      "Step 114: 1.051 sec\n",
      "Step 115: 1.015 sec\n",
      "Step 116: 1.047 sec\n",
      "Step 117: 0.987 sec\n",
      "Step 118: 0.986 sec\n",
      "Step 119: 1.085 sec\n",
      "Step 120: 1.062 sec\n",
      "Step: 120, train_loss: 5.3266, train_accuracy: 87.5000%\n",
      "Step 121: 1.123 sec\n",
      "Step 122: 1.272 sec\n",
      "Step 123: 1.021 sec\n",
      "Step 124: 1.081 sec\n",
      "Step 125: 1.175 sec\n",
      "Step 126: 1.068 sec\n",
      "Step 127: 1.761 sec\n",
      "Step 128: 1.867 sec\n",
      "Step 129: 1.036 sec\n",
      "Step 130: 1.220 sec\n",
      "Step: 130, train_loss: 5.3866, train_accuracy: 81.2500%\n",
      "Step 131: 1.042 sec\n",
      "Step 132: 1.275 sec\n",
      "Step 133: 1.235 sec\n",
      "Step 134: 1.454 sec\n",
      "Step 135: 1.064 sec\n",
      "Step 136: 1.388 sec\n",
      "Step 137: 1.106 sec\n",
      "Step 138: 1.271 sec\n",
      "Step 139: 1.062 sec\n",
      "Step 140: 1.607 sec\n",
      "Step: 140, train_loss: 5.0385, train_accuracy: 87.5000%\n",
      "Step 141: 1.201 sec\n",
      "Step 142: 1.028 sec\n",
      "Step 143: 1.019 sec\n",
      "Step 144: 1.118 sec\n",
      "Step 145: 1.363 sec\n",
      "Step 146: 1.217 sec\n",
      "Step 147: 1.020 sec\n",
      "Step 148: 1.024 sec\n",
      "Step 149: 1.064 sec\n",
      "Step 150: 1.103 sec\n",
      "Step: 150, train_loss: 4.9513, train_accuracy: 87.5000%\n",
      "**  Step 150, val_loss = 4.92, val_accuracy = 87.50%  **\n",
      "Step 151: 1.126 sec\n",
      "Step 152: 1.155 sec\n",
      "Step 153: 1.416 sec\n",
      "Step 154: 1.062 sec\n",
      "Step 155: 1.100 sec\n",
      "Step 156: 1.079 sec\n",
      "Step 157: 1.599 sec\n",
      "Step 158: 1.020 sec\n",
      "Step 159: 1.025 sec\n",
      "Step 160: 1.100 sec\n",
      "Step: 160, train_loss: 4.7998, train_accuracy: 87.5000%\n",
      "Step 161: 1.155 sec\n",
      "Step 162: 1.064 sec\n",
      "Step 163: 1.293 sec\n",
      "Step 164: 1.222 sec\n",
      "Step 165: 1.083 sec\n",
      "Step 166: 1.466 sec\n",
      "Step 167: 1.076 sec\n",
      "Step 168: 1.033 sec\n",
      "Step 169: 1.018 sec\n",
      "Step 170: 1.258 sec\n",
      "Step: 170, train_loss: 4.8054, train_accuracy: 87.5000%\n",
      "Step 171: 1.524 sec\n",
      "Step 172: 1.086 sec\n",
      "Step 173: 1.113 sec\n",
      "Step 174: 1.640 sec\n",
      "Step 175: 1.243 sec\n",
      "Step 176: 1.049 sec\n",
      "Step 177: 1.024 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-93fd337a0d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-f45193fe7af3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m             _, train_loss, train_accuracy = sess.run([train_op,loss,accuracy], feed_dict ={\n\u001b[1;32m    114\u001b[0m                                                           \u001b[0mimages_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtra_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                                                           \u001b[0mlabels_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtra_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                                                           })\n\u001b[1;32m    117\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wjj/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
